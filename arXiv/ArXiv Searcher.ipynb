{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# arXiv Analyzing\n",
    "### Purpose: \n",
    "1. Discover trending research topics\n",
    "2. Discover how papers are related/build on each other (evolution of a topic)\n",
    "3. Discover open questions/things to research/missing pieces of research puzzle\n",
    "4. For fun!\n",
    "\n",
    "### Mechanics:\n",
    "Based on Tim Head's code on \"Analysing the arXiv\" http://betatim.github.io/posts/analysing-the-arxiv/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import stuff\n",
    "import re\n",
    "import time\n",
    "import urllib.request\n",
    "import requests\n",
    "import urllib\n",
    "import datetime\n",
    "import feedparser\n",
    "feedparser._FeedParserMixin.namespaces['http://a9.com/-/spec/opensearch/1.1/'] = 'opensearch'\n",
    "feedparser._FeedParserMixin.namespaces['http://arxiv.org/schemas/atom'] = 'arxiv'\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "import pandas as pd\n",
    "pd.set_option('mode.chained_assignment','warn')\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build up dataframe of paper titles, id's, abstracts, created dates, cateogry, and doi\n",
    "\n",
    "OAI = \"{http://www.openarchives.org/OAI/2.0/}\"\n",
    "ARXIV = \"{http://arxiv.org/OAI/arXiv/}\"\n",
    "\n",
    "#Harvest from quantum physics\n",
    "def harvest(beginDate,endDate):\n",
    "\n",
    "    arxiv=\"physics:quant-ph\"\n",
    "    df = pd.DataFrame(columns=(\"title\", \"abstract\", \"categories\", \"created\", \"id\", \"doi\"))\n",
    "    base_url = \"http://export.arxiv.org/oai2?verb=ListRecords&\"\n",
    "    url = (base_url +\n",
    "           \"from=\"+beginDate+\"&until=\"+endDate+\"&\" +\n",
    "           \"metadataPrefix=arXiv&set=%s\"%arxiv)\n",
    "    \n",
    "    while True:\n",
    "        print(\"fetching\", url)\n",
    "        try:\n",
    "            response = urllib.request.urlopen(url).read()\n",
    "            feed = feedparser.parse(response)\n",
    "            #response = urllib2.urlopen(url) odd line\n",
    "            \n",
    "        except urllib.error.HTTPError as e:\n",
    "            if e.code == 503:\n",
    "                to = int(e.hdrs.get(\"retry-after\", 30))\n",
    "                print(\"Got 503. Retrying after {0:d} seconds.\".format(to))\n",
    "\n",
    "                time.sleep(to)\n",
    "                continue\n",
    "                \n",
    "            else:\n",
    "                raise\n",
    "\n",
    "        root = ET.fromstring(response)\n",
    "\n",
    "        '''for entry in feed.entries:\n",
    "            arxiv_id = entry.id.split('/abs/')[-1]\n",
    "            published = entry.published\n",
    "            meta = record.find(OAI+'metadata')\n",
    "            info = meta.find(ARXIV+\"arXiv\")\n",
    "            created = info.find(ARXIV+\"created\").text\n",
    "            created = datetime.datetime.strptime(created, \"%Y-%m-%d\")\n",
    "            categories = info.find(ARXIV+\"categories\").text\n",
    "            '''\n",
    "            \n",
    "        for record in root.find(OAI+'ListRecords').findall(OAI+\"record\"):\n",
    "            print('meta', meta)\n",
    "            print('author')\n",
    "            arxiv_id = record.find(OAI+'header').find(OAI+'identifier')\n",
    "            meta = record.find(OAI+'metadata')\n",
    "            info = meta.find(ARXIV+\"arXiv\")\n",
    "            created = info.find(ARXIV+\"created\").text\n",
    "            created = datetime.datetime.strptime(created, \"%Y-%m-%d\")\n",
    "            categories = info.find(ARXIV+\"categories\").text\n",
    "        \n",
    "\n",
    "            # if there is more than one DOI use the first one\n",
    "            # often the second one (if it exists at all) refers\n",
    "            # to an eratum or similar\n",
    "            doi = info.find(ARXIV+\"doi\")\n",
    "            if doi is not None:\n",
    "                doi = doi.text.split()[0]\n",
    "                \n",
    "            contents = {'title': info.find(ARXIV+\"title\").text,\n",
    "                        'id': info.find(ARXIV+\"id\").text,#arxiv_id.text[4:],\n",
    "                        'abstract': info.find(ARXIV+\"abstract\").text.strip(),\n",
    "                        'created': created,\n",
    "                        'categories': categories.split(),\n",
    "                        'doi': doi,\n",
    "                        }\n",
    "\n",
    "            df = df.append(contents, ignore_index=True)\n",
    "\n",
    "        # The list of articles returned by the API comes in chunks of\n",
    "        # 1000 articles. The presence of a resumptionToken tells us that\n",
    "        # there is more to be fetched.\n",
    "        token = root.find(OAI+'ListRecords').find(OAI+\"resumptionToken\")\n",
    "        if token is None or token.text is None:\n",
    "            break\n",
    "\n",
    "        else:\n",
    "            url = base_url + \"resumptionToken=%s\"%(token.text)\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import from arXiv\n",
    "Import all articles from quant-ph over date range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetching http://export.arxiv.org/oai2?verb=ListRecords&from=2020-05-01&until=2020-07-20&metadataPrefix=arXiv&set=physics:quant-ph\n",
      "fetching http://export.arxiv.org/oai2?verb=ListRecords&resumptionToken=4731391|1001\n",
      "fetching http://export.arxiv.org/oai2?verb=ListRecords&resumptionToken=4731391|2001\n",
      "fetching http://export.arxiv.org/oai2?verb=ListRecords&resumptionToken=4731391|3001\n",
      "fetching http://export.arxiv.org/oai2?verb=ListRecords&resumptionToken=4731391|4001\n"
     ]
    }
   ],
   "source": [
    "startDate = '2020-05-01'\n",
    "endDate = datetime.date.today().__str__()\n",
    "\n",
    "# Import dataset\n",
    "df = harvest(startDate, endDate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>categories</th>\n",
       "      <th>created</th>\n",
       "      <th>id</th>\n",
       "      <th>doi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5421</th>\n",
       "      <td>Single-photon-level sub-Doppler pump-probe spe...</td>\n",
       "      <td>We propose and demonstrate pump-probe spectros...</td>\n",
       "      <td>[physics.atom-ph, quant-ph]</td>\n",
       "      <td>2020-07-16</td>\n",
       "      <td>2007.08452</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5422</th>\n",
       "      <td>Achieving fair sampling in quantum annealing</td>\n",
       "      <td>Sampling all ground states of a Hamiltonian wi...</td>\n",
       "      <td>[quant-ph]</td>\n",
       "      <td>2020-07-16</td>\n",
       "      <td>2007.08487</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5423</th>\n",
       "      <td>Optical spin initialization of spin-3/2 silico...</td>\n",
       "      <td>Silicon vacancies in silicon carbide have been...</td>\n",
       "      <td>[quant-ph, cond-mat.mes-hall]</td>\n",
       "      <td>2020-07-14</td>\n",
       "      <td>2007.08516</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5424</th>\n",
       "      <td>Ground State Laser Cooling Beyond the Lamb-Dic...</td>\n",
       "      <td>We propose a laser cooling scheme that allows ...</td>\n",
       "      <td>[quant-ph]</td>\n",
       "      <td>1997-06-07</td>\n",
       "      <td>quant-ph/9706017</td>\n",
       "      <td>10.1209/0295-5075/23/1/001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5425</th>\n",
       "      <td>On the Concept of Quantum State Reduction: Inc...</td>\n",
       "      <td>The argument is re-examined that the program o...</td>\n",
       "      <td>[quant-ph]</td>\n",
       "      <td>1998-02-09</td>\n",
       "      <td>quant-ph/9802022</td>\n",
       "      <td>10.4288/jafpos1956.11.107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  \\\n",
       "5421  Single-photon-level sub-Doppler pump-probe spe...   \n",
       "5422       Achieving fair sampling in quantum annealing   \n",
       "5423  Optical spin initialization of spin-3/2 silico...   \n",
       "5424  Ground State Laser Cooling Beyond the Lamb-Dic...   \n",
       "5425  On the Concept of Quantum State Reduction: Inc...   \n",
       "\n",
       "                                               abstract  \\\n",
       "5421  We propose and demonstrate pump-probe spectros...   \n",
       "5422  Sampling all ground states of a Hamiltonian wi...   \n",
       "5423  Silicon vacancies in silicon carbide have been...   \n",
       "5424  We propose a laser cooling scheme that allows ...   \n",
       "5425  The argument is re-examined that the program o...   \n",
       "\n",
       "                         categories    created                id  \\\n",
       "5421    [physics.atom-ph, quant-ph] 2020-07-16        2007.08452   \n",
       "5422                     [quant-ph] 2020-07-16        2007.08487   \n",
       "5423  [quant-ph, cond-mat.mes-hall] 2020-07-14        2007.08516   \n",
       "5424                     [quant-ph] 1997-06-07  quant-ph/9706017   \n",
       "5425                     [quant-ph] 1998-02-09  quant-ph/9802022   \n",
       "\n",
       "                             doi  \n",
       "5421                        None  \n",
       "5422                        None  \n",
       "5423                        None  \n",
       "5424  10.1209/0295-5075/23/1/001  \n",
       "5425   10.4288/jafpos1956.11.107  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(), df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save DataFrame\n",
    "df.to_pickle('./arxiv_articles.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import from Saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load DataFrame\n",
    "df = pd.read_pickle('./arxiv_articles.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter Articles\n",
    "Pick interested articles based on keywords or authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authors = ['Monroe', 'Richerme', 'Hayes']\n",
    "keywords = ['trapped ion', 'trapped ions', 'ion trap', 'ion traps']\n",
    "\n",
    "np.sum(df['abstract'] == keywords[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'author'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2645\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2646\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'author'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-9ff65e39d178>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'author'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2798\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2799\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2800\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2801\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2802\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2646\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2648\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2649\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2650\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'author'"
     ]
    }
   ],
   "source": [
    "df['author']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
