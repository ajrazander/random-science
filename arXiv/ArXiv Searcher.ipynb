{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# arXiv Analyzing\n",
    "### Purpose: \n",
    "1. Discover trending research topics\n",
    "2. Discover how papers are related/build on each other (evolution of a topic)\n",
    "3. Discover open questions/things to research/missing pieces of research puzzle\n",
    "4. For fun!\n",
    "\n",
    "### Mechanics:\n",
    "Based on Tim Head's code on \"Analysing the arXiv\" http://betatim.github.io/posts/analysing-the-arxiv/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import stuff\n",
    "import re\n",
    "import time\n",
    "import urllib.request\n",
    "import requests\n",
    "import urllib\n",
    "import datetime\n",
    "import feedparser\n",
    "feedparser._FeedParserMixin.namespaces['http://a9.com/-/spec/opensearch/1.1/'] = 'opensearch'\n",
    "feedparser._FeedParserMixin.namespaces['http://arxiv.org/schemas/atom'] = 'arxiv'\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "import pandas as pd\n",
    "pd.set_option('mode.chained_assignment','warn')\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build up dataframe of paper titles, id's, abstracts, created dates, cateogry, and doi\n",
    "\n",
    "OAI = \"{http://www.openarchives.org/OAI/2.0/}\"\n",
    "ARXIV = \"{http://arxiv.org/OAI/arXiv/}\"\n",
    "\n",
    "#Harvest from quantum physics\n",
    "def harvest(beginDate,endDate):\n",
    "\n",
    "    arxiv=\"physics:quant-ph\"\n",
    "    df = pd.DataFrame(columns=(\"title\", \"abstract\", \"authors\", \"categories\", \"created\", \"id\", \"doi\"))\n",
    "    base_url = \"http://export.arxiv.org/oai2?verb=ListRecords&\"\n",
    "    url = (base_url +\n",
    "           \"from=\"+beginDate+\"&until=\"+endDate+\"&\" +\n",
    "           \"metadataPrefix=arXiv&set=%s\"%arxiv)\n",
    "\n",
    "    while True:\n",
    "        print(\"fetching\", url)\n",
    "        try:\n",
    "            response = urllib.request.urlopen(url).read()\n",
    "\n",
    "        except urllib.error.HTTPError as e:\n",
    "            if e.code == 503:\n",
    "                to = int(e.hdrs.get(\"retry-after\", 30))\n",
    "                print(\"Got 503. Retrying after {0:d} seconds.\".format(to))\n",
    "\n",
    "                time.sleep(to)\n",
    "                continue\n",
    "\n",
    "            else:\n",
    "                raise\n",
    "\n",
    "        root = ET.fromstring(response)\n",
    "\n",
    "        for record in root.find(OAI+'ListRecords').findall(OAI+\"record\"):\n",
    "            authors = []\n",
    "            arxiv_id = record.find(OAI+'header').find(OAI+'identifier')\n",
    "            meta = record.find(OAI+'metadata')\n",
    "            info = meta.find(ARXIV+\"arXiv\")\n",
    "            created = info.find(ARXIV+\"created\").text\n",
    "            created = datetime.datetime.strptime(created, \"%Y-%m-%d\")\n",
    "            categories = info.find(ARXIV+\"categories\").text\n",
    "            try:\n",
    "                for names in info[3]:\n",
    "                    authors.append(names[1].text+' '+names[0].text)\n",
    "            except:\n",
    "                authors.append('blank')\n",
    "\n",
    "\n",
    "            # if there is more than one DOI use the first one\n",
    "            # often the second one (if it exists at all) refers\n",
    "            # to an eratum or similar\n",
    "            doi = info.find(ARXIV+\"doi\")\n",
    "            if doi is not None:\n",
    "                doi = doi.text.split()[0]\n",
    "\n",
    "            contents = {'title': info.find(ARXIV+\"title\").text,\n",
    "                        'id': info.find(ARXIV+\"id\").text,#arxiv_id.text[4:],\n",
    "                        'abstract': info.find(ARXIV+\"abstract\").text.strip(),\n",
    "                        'authors': authors,\n",
    "                        'created': created,\n",
    "                        'categories': categories.split(),\n",
    "                        'doi': doi,\n",
    "                        }\n",
    "\n",
    "            df = df.append(contents, ignore_index=True)\n",
    "\n",
    "        # The list of articles returned by the API comes in chunks of\n",
    "        # 1000 articles. The presence of a resumptionToken tells us that\n",
    "        # there is more to be fetched.\n",
    "        token = root.find(OAI+'ListRecords').find(OAI+\"resumptionToken\")\n",
    "        if token is None or token.text is None:\n",
    "            break\n",
    "\n",
    "        else:\n",
    "            url = base_url + \"resumptionToken=%s\"%(token.text)\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import from arXiv\n",
    "Import all articles from quant-ph over date range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetching http://export.arxiv.org/oai2?verb=ListRecords&from=2019-01-01&until=2020-07-21&metadataPrefix=arXiv&set=physics:quant-ph\n",
      "fetching http://export.arxiv.org/oai2?verb=ListRecords&resumptionToken=4736579|1001\n",
      "fetching http://export.arxiv.org/oai2?verb=ListRecords&resumptionToken=4736579|2001\n",
      "fetching http://export.arxiv.org/oai2?verb=ListRecords&resumptionToken=4736579|3001\n",
      "fetching http://export.arxiv.org/oai2?verb=ListRecords&resumptionToken=4736579|4001\n",
      "fetching http://export.arxiv.org/oai2?verb=ListRecords&resumptionToken=4736579|5001\n",
      "fetching http://export.arxiv.org/oai2?verb=ListRecords&resumptionToken=4736579|6001\n",
      "fetching http://export.arxiv.org/oai2?verb=ListRecords&resumptionToken=4736579|7001\n",
      "fetching http://export.arxiv.org/oai2?verb=ListRecords&resumptionToken=4736579|8001\n",
      "fetching http://export.arxiv.org/oai2?verb=ListRecords&resumptionToken=4736579|9001\n",
      "fetching http://export.arxiv.org/oai2?verb=ListRecords&resumptionToken=4736579|10001\n",
      "fetching http://export.arxiv.org/oai2?verb=ListRecords&resumptionToken=4736579|11001\n",
      "fetching http://export.arxiv.org/oai2?verb=ListRecords&resumptionToken=4736579|12001\n",
      "fetching http://export.arxiv.org/oai2?verb=ListRecords&resumptionToken=4736579|13001\n",
      "fetching http://export.arxiv.org/oai2?verb=ListRecords&resumptionToken=4736579|14001\n",
      "fetching http://export.arxiv.org/oai2?verb=ListRecords&resumptionToken=4736579|15001\n",
      "fetching http://export.arxiv.org/oai2?verb=ListRecords&resumptionToken=4736579|16001\n",
      "fetching http://export.arxiv.org/oai2?verb=ListRecords&resumptionToken=4736579|17001\n",
      "fetching http://export.arxiv.org/oai2?verb=ListRecords&resumptionToken=4736579|18001\n"
     ]
    }
   ],
   "source": [
    "startDate = '2019-01-01'\n",
    "endDate = datetime.date.today().__str__()\n",
    "\n",
    "# Import dataset\n",
    "df = harvest(startDate, endDate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>authors</th>\n",
       "      <th>categories</th>\n",
       "      <th>created</th>\n",
       "      <th>id</th>\n",
       "      <th>doi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Geometric Phase and Superconducting Flux Quant...</td>\n",
       "      <td>In a ring of s-wave superconducting material t...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[quant-ph]</td>\n",
       "      <td>2007-04-05</td>\n",
       "      <td>0704.0803</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A remark on helical waveguides</td>\n",
       "      <td>Motivated by a proposal to create an optical h...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[quant-ph, cond-mat.mes-hall, math-ph, math.MP]</td>\n",
       "      <td>2007-04-20</td>\n",
       "      <td>0704.2770</td>\n",
       "      <td>10.1016/j.physleta.2007.05.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nontrivial edge coupling from a Dirichlet netw...</td>\n",
       "      <td>In distinction to the Neumann case the squeezi...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[math-ph, cond-mat.mes-hall, math.MP, math.SP,...</td>\n",
       "      <td>2007-04-23</td>\n",
       "      <td>0704.2912</td>\n",
       "      <td>10.1088/1751-8113/40/26/F02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>On the dense point and absolutely continuous s...</td>\n",
       "      <td>We consider Schr\\\"odinger operator in dimensio...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[math-ph, cond-mat.mes-hall, math.MP, math.SP,...</td>\n",
       "      <td>2007-05-10</td>\n",
       "      <td>0705.1407</td>\n",
       "      <td>10.1007/s11005-007-0191-x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A \"hybrid plane\" with spin-orbit interaction</td>\n",
       "      <td>In this paper we attempt to reconstruct one of...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[math-ph, cond-mat.mes-hall, math.MP, math.SP,...</td>\n",
       "      <td>2007-05-17</td>\n",
       "      <td>0705.2487</td>\n",
       "      <td>10.1134/S1061920807040085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Geometric Phase and Superconducting Flux Quant...   \n",
       "1                     A remark on helical waveguides   \n",
       "2  Nontrivial edge coupling from a Dirichlet netw...   \n",
       "3  On the dense point and absolutely continuous s...   \n",
       "4       A \"hybrid plane\" with spin-orbit interaction   \n",
       "\n",
       "                                            abstract authors  \\\n",
       "0  In a ring of s-wave superconducting material t...      []   \n",
       "1  Motivated by a proposal to create an optical h...      []   \n",
       "2  In distinction to the Neumann case the squeezi...      []   \n",
       "3  We consider Schr\\\"odinger operator in dimensio...      []   \n",
       "4  In this paper we attempt to reconstruct one of...      []   \n",
       "\n",
       "                                          categories    created         id  \\\n",
       "0                                         [quant-ph] 2007-04-05  0704.0803   \n",
       "1    [quant-ph, cond-mat.mes-hall, math-ph, math.MP] 2007-04-20  0704.2770   \n",
       "2  [math-ph, cond-mat.mes-hall, math.MP, math.SP,... 2007-04-23  0704.2912   \n",
       "3  [math-ph, cond-mat.mes-hall, math.MP, math.SP,... 2007-05-10  0705.1407   \n",
       "4  [math-ph, cond-mat.mes-hall, math.MP, math.SP,... 2007-05-17  0705.2487   \n",
       "\n",
       "                              doi  \n",
       "0                            None  \n",
       "1  10.1016/j.physleta.2007.05.013  \n",
       "2     10.1088/1751-8113/40/26/F02  \n",
       "3       10.1007/s11005-007-0191-x  \n",
       "4       10.1134/S1061920807040085  "
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save DataFrame\n",
    "df.to_pickle('./arxiv_articles.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import from Saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load DataFrame\n",
    "df = pd.read_pickle('./arxiv_articles.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter Articles\n",
    "Pick interested articles based on keywords or authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authors = ['Monroe', 'Richerme', 'Hayes']\n",
    "keywords = ['trapped ion', 'trapped ions', 'ion trap', 'ion traps']\n",
    "\n",
    "np.sum(df['abstract'] == keywords[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'author'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2645\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2646\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'author'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-9ff65e39d178>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'author'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2798\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2799\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2800\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2801\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2802\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2646\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2648\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2649\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2650\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'author'"
     ]
    }
   ],
   "source": [
    "df['author']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
